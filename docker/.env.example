# Auto-Claude Docker Environment Configuration
# Copy this file to .env and fill in your values

# =============================================================================
# DATABASE (Required for multi-user support)
# =============================================================================

# PostgreSQL password - use a strong, random password
# Generate with: openssl rand -base64 32
POSTGRES_PASSWORD=changeme-use-strong-password

# PostgreSQL port (external access, default: 5432)
POSTGRES_PORT=5432

# =============================================================================
# JWT AUTHENTICATION (Required)
# =============================================================================

# Secret key for signing JWT tokens
# Generate with: openssl rand -hex 32
JWT_SECRET_KEY=changeme-generate-with-openssl-rand-hex-32

# Access token expiration in minutes (default: 30)
JWT_ACCESS_TOKEN_EXPIRE_MINUTES=30

# Refresh token expiration in days (default: 30)
JWT_REFRESH_TOKEN_EXPIRE_DAYS=30

# =============================================================================
# CREDENTIAL ENCRYPTION (Recommended for storing API keys per project)
# =============================================================================

# Fernet key for encrypting stored credentials
# Generate with: python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
CREDENTIAL_ENCRYPTION_KEY=

# =============================================================================
# CLAUDE AUTHENTICATION (Required for Auto-Claude builds)
# =============================================================================
# Auto Claude uses Claude Code OAuth authentication.
# NOTE: ANTHROPIC_API_KEY is intentionally NOT used for builds to prevent
# silent billing to API credits when OAuth is misconfigured.

# OAuth token from Claude CLI (required for builds)
# Run: claude setup-token
CLAUDE_CODE_OAUTH_TOKEN=

# Anthropic API key (for other features, NOT used for Auto-Claude builds)
# This is passed through for potential future use or other integrations
ANTHROPIC_API_KEY=

# =============================================================================
# GITHUB AUTHENTICATION
# =============================================================================

# GitHub Personal Access Token for cloning private repositories
# Create at: https://github.com/settings/tokens
# Required scopes: repo (for private repos)
GITHUB_TOKEN=

# =============================================================================
# REPOSITORY AUTO-CLONE
# =============================================================================

# Comma-separated list of repository URLs to clone on container startup
# Example: https://github.com/user/repo1,https://github.com/user/repo2
CLONE_REPOS=

# =============================================================================
# WEB UI SETTINGS
# =============================================================================

# Port for web UI (default: 8080)
WEB_PORT=8080

# =============================================================================
# AUTO-CLAUDE SETTINGS
# =============================================================================

# Default git branch for operations
DEFAULT_BRANCH=main

# Enable debug mode
DEBUG=false

# Model override for Auto-Claude agents (OPTIONAL)
# Default: claude-opus-4-5-20251101
# AUTO_BUILD_MODEL=claude-opus-4-5-20251101

# =============================================================================
# ELECTRON MCP SERVER (OPTIONAL)
# =============================================================================
# Enable Electron MCP server for AI agents to interact with and validate
# Electron desktop applications. This allows QA agents to capture screenshots,
# inspect windows, and validate Electron apps during the review process.

# Enable Electron MCP integration (default: false)
# ELECTRON_MCP_ENABLED=true

# Chrome DevTools debugging port for Electron connection (default: 9222)
# ELECTRON_DEBUG_PORT=9222

# =============================================================================
# GRAPHITI MEMORY INTEGRATION (Optional - Enhanced cross-session memory)
# =============================================================================
# Enable Graphiti-based persistent memory layer for cross-session context
# retention. Uses FalkorDB as the graph database backend.
#
# V2 supports multiple LLM and embedder providers:
#   - OpenAI (default)
#   - Anthropic (LLM only, use with Voyage for embeddings)
#   - Azure OpenAI
#   - Ollama (local, fully offline)
#   - Google AI (Gemini)

# Enable Graphiti memory integration
GRAPHITI_ENABLED=false

# =============================================================================
# GRAPHITI: Provider Selection
# =============================================================================
# Choose which providers to use for LLM and embeddings.
# Default is "openai" for both.

# LLM provider: openai | anthropic | azure_openai | ollama | google
# GRAPHITI_LLM_PROVIDER=openai

# Embedder provider: openai | voyage | azure_openai | ollama | google
# GRAPHITI_EMBEDDER_PROVIDER=openai

# =============================================================================
# GRAPHITI: OpenAI Provider (Default)
# =============================================================================
# Use OpenAI for both LLM and embeddings. This is the simplest setup.
# Required: OPENAI_API_KEY

# OpenAI API Key (also used for Graphiti embeddings by default)
OPENAI_API_KEY=

# OpenAI Model for LLM (default: gpt-4o-mini)
GRAPHITI_MODEL_NAME=gpt-4o-mini

# OpenAI Model for embeddings (default: text-embedding-3-small)
# Available: text-embedding-3-small (1536 dim), text-embedding-3-large (3072 dim)
GRAPHITI_EMBEDDING_MODEL=text-embedding-3-small

# =============================================================================
# GRAPHITI: Anthropic Provider (LLM only)
# =============================================================================
# Use Anthropic for LLM. Requires separate embedder (use Voyage or OpenAI).
# Example: GRAPHITI_LLM_PROVIDER=anthropic, GRAPHITI_EMBEDDER_PROVIDER=voyage
#
# Note: ANTHROPIC_API_KEY above is used for Claude Code authentication.
# For Graphiti with Anthropic, the same key is used.

# Anthropic Model for Graphiti (default: claude-sonnet-4-5-latest)
# GRAPHITI_ANTHROPIC_MODEL=claude-sonnet-4-5-latest

# =============================================================================
# GRAPHITI: Voyage AI Provider (Embeddings only)
# =============================================================================
# Use Voyage AI for embeddings. Commonly paired with Anthropic LLM.
# Get API key from: https://www.voyageai.com/

# Voyage AI API Key
# VOYAGE_API_KEY=pa-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Voyage Embedding Model (default: voyage-3)
# Available: voyage-3 (1024 dim), voyage-3-lite (512 dim)
# VOYAGE_EMBEDDING_MODEL=voyage-3

# =============================================================================
# GRAPHITI: Google AI Provider (Gemini)
# =============================================================================
# Use Google AI (Gemini) for both LLM and embeddings.
# Get API key from: https://aistudio.google.com/apikey

# Google AI API Key
# GOOGLE_API_KEY=AIzaSyxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Google LLM Model (default: gemini-2.0-flash)
# GOOGLE_LLM_MODEL=gemini-2.0-flash

# Google Embedding Model (default: text-embedding-004)
# GOOGLE_EMBEDDING_MODEL=text-embedding-004

# =============================================================================
# GRAPHITI: Azure OpenAI Provider
# =============================================================================
# Use Azure OpenAI for both LLM and embeddings.
# Requires Azure OpenAI deployment with appropriate models.

# Azure OpenAI API Key
# AZURE_OPENAI_API_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Azure OpenAI Base URL (your Azure endpoint)
# AZURE_OPENAI_BASE_URL=https://your-resource.openai.azure.com/openai/deployments/your-deployment

# Azure OpenAI Deployment Names
# AZURE_OPENAI_LLM_DEPLOYMENT=gpt-4
# AZURE_OPENAI_EMBEDDING_DEPLOYMENT=text-embedding-3-small

# =============================================================================
# GRAPHITI: Ollama Provider (Local/Offline)
# =============================================================================
# Use Ollama for fully offline operation. No API keys required.
# Requires Ollama running locally with appropriate models pulled.
#
# Prerequisites:
#   1. Install Ollama: https://ollama.ai/
#   2. Pull models: ollama pull deepseek-r1:7b && ollama pull nomic-embed-text
#   3. Start Ollama server (usually auto-starts)

# Ollama Server URL (default: http://localhost:11434)
# OLLAMA_BASE_URL=http://localhost:11434

# Ollama LLM Model
# Popular choices: deepseek-r1:7b, llama3.2:3b, mistral:7b, phi3:medium
# OLLAMA_LLM_MODEL=deepseek-r1:7b

# Ollama Embedding Model
# Popular choices: nomic-embed-text (768 dim), mxbai-embed-large (1024 dim)
# OLLAMA_EMBEDDING_MODEL=nomic-embed-text

# Ollama Embedding Dimension (REQUIRED for Ollama embeddings)
# Must match your embedding model's output dimension
# Common values: nomic-embed-text=768, mxbai-embed-large=1024, all-minilm=384
# OLLAMA_EMBEDDING_DIM=768

# =============================================================================
# GRAPHITI: FalkorDB Connection Settings
# =============================================================================
# Configure the FalkorDB graph database connection.
# These are set automatically in docker-compose, but can be overridden.

# FalkorDB port (external access, default: 6380, internal: 6379)
FALKORDB_PORT=6380

# Graphiti MCP server port
GRAPHITI_MCP_PORT=8000

# Graph Database Name (default: auto_claude_memory)
# GRAPHITI_DATABASE=auto_claude_memory

# Disable Graphiti telemetry (default: true)
# GRAPHITI_TELEMETRY_ENABLED=false

# =============================================================================
# GRAPHITI: Example Configurations
# =============================================================================
#
# --- Example 1: OpenAI (simplest) ---
# GRAPHITI_ENABLED=true
# GRAPHITI_LLM_PROVIDER=openai
# GRAPHITI_EMBEDDER_PROVIDER=openai
# OPENAI_API_KEY=sk-xxxxxxxx
#
# --- Example 2: Anthropic + Voyage (high quality) ---
# GRAPHITI_ENABLED=true
# GRAPHITI_LLM_PROVIDER=anthropic
# GRAPHITI_EMBEDDER_PROVIDER=voyage
# ANTHROPIC_API_KEY=sk-ant-xxxxxxxx
# VOYAGE_API_KEY=pa-xxxxxxxx
#
# --- Example 3: Ollama (fully offline) ---
# GRAPHITI_ENABLED=true
# GRAPHITI_LLM_PROVIDER=ollama
# GRAPHITI_EMBEDDER_PROVIDER=ollama
# OLLAMA_LLM_MODEL=deepseek-r1:7b
# OLLAMA_EMBEDDING_MODEL=nomic-embed-text
# OLLAMA_EMBEDDING_DIM=768
#
# --- Example 4: Azure OpenAI (enterprise) ---
# GRAPHITI_ENABLED=true
# GRAPHITI_LLM_PROVIDER=azure_openai
# GRAPHITI_EMBEDDER_PROVIDER=azure_openai
# AZURE_OPENAI_API_KEY=xxxxxxxx
# AZURE_OPENAI_BASE_URL=https://your-resource.openai.azure.com/...
# AZURE_OPENAI_LLM_DEPLOYMENT=gpt-4
# AZURE_OPENAI_EMBEDDING_DEPLOYMENT=text-embedding-3-small
#
# --- Example 5: Google AI (Gemini) ---
# GRAPHITI_ENABLED=true
# GRAPHITI_LLM_PROVIDER=google
# GRAPHITI_EMBEDDER_PROVIDER=google
# GOOGLE_API_KEY=AIzaSyxxxxxxxx

# =============================================================================
# LINEAR INTEGRATION (Optional)
# =============================================================================
# Enable Linear integration for real-time progress tracking in Linear.
# Get your API key from: https://linear.app/YOUR-TEAM/settings/api

# Linear API Key (OPTIONAL - enables Linear integration)
# LINEAR_API_KEY=lin_api_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Pre-configured Team ID (OPTIONAL - will auto-detect if not set)
# LINEAR_TEAM_ID=

# Pre-configured Project ID (OPTIONAL - will create project if not set)
# LINEAR_PROJECT_ID=
